{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "n_splits = 5\n",
    "seed = 42\n",
    "path = 'E:/BDCI Match/'\n",
    "\n",
    "traindataFile = u\"E:/BDCI Match/train_preproceed.csv\"\n",
    "testFile = u\"E:/BDCI Match/test.zip\"\n",
    "\n",
    "z = zipfile.ZipFile(testFile)\n",
    "\n",
    "df1 = pd.read_csv(z.open(z.namelist()[0]))\n",
    "\n",
    "df = pd.read_csv(traindataFile)\n",
    "# df = df[[\"service_type\",\"current_service\"]]\n",
    "\n",
    "#对预测标签重新编码\n",
    "le = LabelEncoder()\n",
    "#获取预测结果的所有取值\n",
    "res_labels = df[\"current_service\"].unique()\n",
    "\n",
    "le.fit(res_labels)\n",
    "df[\"current_service\"] = le.transform(df[\"current_service\"])\n",
    "\n",
    "# 构造原始数据\n",
    "train = df\n",
    "test = df1\n",
    "\n",
    "y = train.pop('current_service')\n",
    "train_id = train.pop('user_id')\n",
    "\n",
    "X = train\n",
    "train_col = train.columns\n",
    "\n",
    "for i in train_col:\n",
    "    X_test[i] = X_test[i].replace(\"\\\\N\",-1)\n",
    "\n",
    "X_test = test[train_col]\n",
    "test_id = test['user_id']\n",
    "\n",
    "X,y,X_test = X.values,y,X_test.values\n",
    "\n",
    "\n",
    "# lgb 参数\n",
    "params={\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 15,\n",
    "    'metric': {'rmse'},  #'metric': {'l2', 'auc'},\n",
    "    'num_leaves':39,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'num_iterations': 10000,\n",
    "    'max_depth': -1,\n",
    "    \"lambda_l1\":0.1,\n",
    "    \"lambda_l2\":0.2,\n",
    "    \"silent\":True\n",
    "}\n",
    "\n",
    "\n",
    "# 采取k折模型方案\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 自定义F1评价函数\n",
    "def f1_score_vali(preds, data_vali):\n",
    "    labels = data_vali.get_label()\n",
    "    preds = np.argmax(preds.reshape(15, -1), axis=0)\n",
    "    score_vali = f1_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    return 'f1_score', score_vali, True\n",
    "\n",
    "xx_score = []\n",
    "cv_pred = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits,random_state=seed,shuffle=True)\n",
    "for index,(train_index,test_index) in enumerate(skf.split(X,y)):\n",
    "    print(index)\n",
    "\n",
    "    X_train,X_valid,y_train,y_valid = X[train_index],X[test_index],y[train_index],y[test_index]\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    validation_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    clf=lgb.train(params,train_data,num_boost_round=100000,valid_sets=[validation_data],early_stopping_rounds=50,feval=f1_score_vali,verbose_eval=1)\n",
    "\n",
    "    xx_pred = clf.predict(X_valid,num_iteration=clf.best_iteration)\n",
    "\n",
    "    xx_pred = [np.argmax(x) for x in xx_pred]\n",
    "\n",
    "    xx_score.append(f1_score(y_valid,xx_pred,average='weighted'))\n",
    "\n",
    "    y_test = clf.predict(X_test,num_iteration=clf.best_iteration)\n",
    "\n",
    "    y_test = [np.argmax(x) for x in y_test]\n",
    "\n",
    "    if index == 0:\n",
    "        cv_pred = np.array(y_test).reshape(-1, 1)\n",
    "    else:\n",
    "        cv_pred = np.hstack((cv_pred, np.array(y_test).reshape(-1, 1)))\n",
    "\n",
    "# 投票\n",
    "submit = []\n",
    "for line in cv_pred:\n",
    "    submit.append(np.argmax(np.bincount(line)))\n",
    "\n",
    "# 保存结果\n",
    "df_test = pd.DataFrame()\n",
    "df_test['id'] = list(test_id.unique())\n",
    "df_test['predict'] = submit\n",
    "df_test['predict'] = list(le.inverse_transform(df_test['predict']))\n",
    "\n",
    "df_test.to_csv(\"E:/BDCI Match/sample_submission.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
