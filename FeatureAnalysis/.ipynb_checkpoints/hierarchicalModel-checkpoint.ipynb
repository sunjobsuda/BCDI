{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-71fb401a484a>, line 163)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-71fb401a484a>\"\u001b[1;36m, line \u001b[1;32m163\u001b[0m\n\u001b[1;33m    seed =\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#分类训练模型  1. service_type=3 <=> current_service=99104722\n",
    "#分类训练模型  2. service_type=1 <=> current_service={90063345: 0, 90109916: 1, 90155946: 2}\n",
    "#分类训练模型  3. service_type=4 <=> current_service={89016252: 0, 89016253: 1, 89016259: 2, 89950166: 3, 89950167: 4, 89950168: 5, 99999825: 6, 99999826: 7, 99999827: 8, 99999828: 9, 99999830: 10}\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "n_splits = 5\n",
    "seed = 35\n",
    "path = 'E:/BDCI Match/'\n",
    "\n",
    "#文件路径\n",
    "traindataFile = path + 'train.csv'\n",
    "testdataFile = path+ 'test.csv'\n",
    "\n",
    "#文件加载\n",
    "train = pd.read_csv(traindataFile)\n",
    "test = pd.read_csv(testdataFile)\n",
    "\n",
    "#current_service为99104722的记录可以剔除，因为service_type=3 <=> current_service=99104722\n",
    "train1 = train.loc[train['service_type']==1]\n",
    "train1 = train1.reset_index()\n",
    "\n",
    "train2 = train.loc[train['service_type']==4]\n",
    "train2 = train2.reset_index()\n",
    "\n",
    "test1 = test.loc[test['service_type']==1]\n",
    "test1 = test1.reset_index()\n",
    "test2 = test.loc[test['service_type']==4]\n",
    "test2 = test2.reset_index()\n",
    "test3 = test.loc[test['service_type']==3]\n",
    "test3 = test3.reset_index()\n",
    "test_id3 = test3['user_id']\n",
    "\n",
    "# 对标签编码 映射关系\n",
    "label2current_service1 = dict(zip(range(0,len(set(train1['current_service']))),sorted(list(set(train1['current_service'])))))\n",
    "current_service2label1 = dict(zip(sorted(list(set(train1['current_service']))),range(0,len(set(train1['current_service'])))))\n",
    "\n",
    "label2current_service2 = dict(zip(range(0,len(set(train2['current_service']))),sorted(list(set(train2['current_service'])))))\n",
    "current_service2label2 = dict(zip(sorted(list(set(train2['current_service']))),range(0,len(set(train2['current_service'])))))\n",
    "\n",
    "# 原始数据的标签映射\n",
    "train1['current_service'] = train1['current_service'].map(current_service2label1)\n",
    "train2['current_service'] = train2['current_service'].map(current_service2label2)\n",
    "\n",
    "print('train1 data shape',train1.shape)\n",
    "print('train1 data of user_id shape',len(set(train1['user_id'])))\n",
    "print('train1 data of current_service shape',current_service2label1)\n",
    "\n",
    "print('test1 data shape',test1.shape)\n",
    "print('test1 data of user_id shape',len(set(test1['user_id'])))\n",
    "\n",
    "print('train2 data shape',train2.shape)\n",
    "print('train2 data of user_id shape',len(set(train2['user_id'])))\n",
    "print('train2 data of current_service shape',current_service2label2)\n",
    "\n",
    "print('test2 data shape',test2.shape)\n",
    "print('test2 data of user_id shape',len(set(test2['user_id'])))\n",
    "\n",
    "print('test3 data shape',test3.shape)\n",
    "print('test3 data of user_id shape',len(set(test3['user_id'])))\n",
    "\n",
    "\n",
    "# t1 = train1.loc[(train1['current_service']!=0)&(train1['current_service']!=1)&(train1['current_service']!=2)]\n",
    "# print(t1)\n",
    "# exit()\n",
    "\n",
    "# 构造原始数据\n",
    "index1 = train1.pop('index')\n",
    "y1 = train1.pop('current_service')\n",
    "train_id1 = train1.pop('user_id')\n",
    "train1.pop('service_type')\n",
    "X1 = train1\n",
    "train_col = train1.columns\n",
    "\n",
    "X1_test = test1[train_col]\n",
    "test_id1 = test1['user_id']\n",
    "\n",
    "# 构造原始数据\n",
    "index2 = train2.pop('index')\n",
    "y2 = train2.pop('current_service')\n",
    "train_id2 = train2.pop('user_id')\n",
    "train2.pop('service_type')\n",
    "X2 = train2\n",
    "train_col = train2.columns\n",
    "\n",
    "X2_test = test2[train_col]\n",
    "test_id2 = test2['user_id']\n",
    "\n",
    "# 数据有问题数据\n",
    "for i in train_col:\n",
    "    X1[i] = X1[i].replace(\"\\\\N\",-1)\n",
    "    X2[i] = X2[i].replace(\"\\\\N\",-1)\n",
    "    X1_test[i] = X1_test[i].replace(\"\\\\N\",-1)\n",
    "    X2_test[i] = X2_test[i].replace(\"\\\\N\",-1)\n",
    "\n",
    "    \n",
    "X1,y1,X1_test = X1.values,y1,X1_test.values\n",
    "X2,y2,X2_test = X2.values,y2,X2_test.values\n",
    "\n",
    "\n",
    "# 采取k折模型方案\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# lgb 参数\n",
    "params1={\n",
    "    \"learning_rate\":0.02,\n",
    "    \"lambda_l1\":0.1,\n",
    "    \"lambda_l2\":0.2,\n",
    "    \"max_depth\":-1,\n",
    "    \"objective\":\"multiclass\",\n",
    "    \"num_class\":3,\n",
    "    \"silent\":True,\n",
    "}\n",
    "\n",
    "params2={\n",
    "    \"learning_rate\":0.02,\n",
    "    \"lambda_l1\":0.1,\n",
    "    \"lambda_l2\":0.2,\n",
    "    \"max_depth\":-1,\n",
    "    \"objective\":\"multiclass\",\n",
    "    \"num_class\":11,\n",
    "    \"silent\":True,\n",
    "}\n",
    "\n",
    "# 自定义F1评价函数\n",
    "def f1_score_vali3(preds, data_vali):\n",
    "#     print(preds.shape)\n",
    "#     print(preds)\n",
    "    labels = data_vali.get_label()\n",
    "    preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "    score_vali = f1_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    return 'f1_score', score_vali, True\n",
    "\n",
    "# 自定义F1评价函数\n",
    "def f1_score_vali11(preds, data_vali):\n",
    "#     print(preds.shape)\n",
    "#     print(preds)\n",
    "    labels = data_vali.get_label()\n",
    "    preds = np.argmax(preds.reshape(11, -1), axis=0)\n",
    "    score_vali = f1_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    return 'f1_score', score_vali, True\n",
    "\n",
    "#k折训练模型\n",
    "def trainKfold(X, y, X_test, params):\n",
    "    xx_score = []\n",
    "    cv_pred = []\n",
    "   \n",
    "    skf = StratifiedKFold(n_splits=n_splits,random_state=seed,shuffle=True)\n",
    "    for index,(train_index,test_index) in enumerate(skf.split(X,y)):\n",
    "        print(index)\n",
    "\n",
    "        X_train,X_valid,y_train,y_valid = X[train_index],X[test_index],y[train_index],y[test_index]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        validation_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        if params['num_class'] ==3:\n",
    "            clf=lgb.train(params,train_data,num_boost_round=10000,valid_sets=[validation_data],early_stopping_rounds=100,feval=f1_score_vali3,verbose_eval=20)\n",
    "        else:\n",
    "            clf=lgb.train(params,train_data,num_boost_round=10000,valid_sets=[validation_data],early_stopping_rounds=100,feval=f1_score_vali11,verbose_eval=20)\n",
    "\n",
    "        xx_pred = clf.predict(X_valid,num_iteration=clf.best_iteration)\n",
    "\n",
    "        xx_pred = [np.argmax(x) for x in xx_pred]\n",
    "\n",
    "        xx_score.append(f1_score(y_valid,xx_pred,average='weighted'))\n",
    "\n",
    "        y_test = clf.predict(X_test,num_iteration=clf.best_iteration)\n",
    "\n",
    "        y_test = [np.argmax(x) for x in y_test]\n",
    "\n",
    "        if index == 0:\n",
    "            cv_pred = np.array(y_test).reshape(-1, 1)\n",
    "        else:\n",
    "            cv_pred = np.hstack((cv_pred, np.array(y_test).reshape(-1, 1)))\n",
    "\n",
    "    # 投票\n",
    "    submit = []\n",
    "    for line in cv_pred:\n",
    "        submit.append(np.argmax(np.bincount(line)))\n",
    "    return submit\n",
    "\n",
    "submit1 = trainKfold(X1, y1, X1_test, params1)\n",
    "submit2 = trainKfold(X2, y2, X2_test, params2)\n",
    "submit3 = [99104722]*len(list(test_id3.unique()))\n",
    "\n",
    "\n",
    "temp1 = pd.DataFrame()\n",
    "temp2 = pd.DataFrame()\n",
    "temp1['submit1'] = submit1\n",
    "temp1['submit1'] = temp1['submit1'].map(label2current_service1)\n",
    "temp2['submit2'] = submit2\n",
    "temp2['submit2'] = temp2['submit2'].map(label2current_service2)\n",
    "\n",
    "# 保存结果\n",
    "df_test = pd.DataFrame()\n",
    "df_test['id'] = list(test_id1.unique())+list(test_id2.unique())+list(test_id3.unique())\n",
    "df_test['predict'] = list(temp1['submit1'])+list(temp2['submit2'])+list(submit3)\n",
    "# df_test['predict'] = df_test['predict'].map(label2current_service)\n",
    "\n",
    "df_test.to_csv(path+ './result/sample_submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
